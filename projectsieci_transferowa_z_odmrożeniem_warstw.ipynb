{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Patryk-O/Konwulcyjne-sieci-neuronowe/blob/main/projectsieci_transferowa_z_odmro%C5%BCeniem_warstw.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lbkCqsgB9OXR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from google.colab import drive\n",
        "from matplotlib import pyplot as plt\n",
        "from keras.utils import image_dataset_from_directory\n",
        "from keras import layers, Model, Input\n",
        "from keras.models import Sequential\n",
        "from keras.utils import plot_model\n",
        "from keras.metrics import CategoricalAccuracy, TruePositives, TrueNegatives, FalsePositives, FalseNegatives,Accuracy\n",
        "from keras import layers\n",
        "from tensorflow import data as tf_data\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.applications import Xception, xception"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngvmrB1oA1jZ",
        "outputId": "d7a05956-74d5-4489-abd5-a56571172d80"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "replace grzyby/test/H1/H1_102a_19.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "!unzip -q \"/content/drive/MyDrive/grzyby/grzyby.zip\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7z4QcSTa-fhQ"
      },
      "outputs": [],
      "source": [
        "\n",
        "directory_test = '/content/grzyby/test/'\n",
        "directory_train = '/content/grzyby/train/'\n",
        "\n",
        "H1_train = os.path.join(directory_train, 'H1')\n",
        "H2_train = os.path.join(directory_train, 'H2')\n",
        "H3_train = os.path.join(directory_train, 'H3')\n",
        "H5_train = os.path.join(directory_train, 'H5')\n",
        "H6_train = os.path.join(directory_train, 'H6')\n",
        "\n",
        "\n",
        "H1_test = os.path.join(directory_test, 'H1')\n",
        "H2_test = os.path.join(directory_test, 'H2')\n",
        "H3_test = os.path.join(directory_test, 'H3')\n",
        "H5_test = os.path.join(directory_test, 'H5')\n",
        "H6_test = os.path.join(directory_test, 'H6')\n",
        "\n",
        "\n",
        "print('Zbiór uczący')\n",
        "print(f'Liczba zdjęć H1 {len(os.listdir(H1_train))}')\n",
        "print(f'Liczba zdjęć H2 {len(os.listdir(H2_train))}')\n",
        "print(f'Liczba zdjęć H3 {len(os.listdir(H3_train))}')\n",
        "print(f'Liczba zdjęć H5 {len(os.listdir(H5_train))}')\n",
        "print(f'Liczba zdjęć H6 {len(os.listdir(H6_train))}')\n",
        "\n",
        "\n",
        "print('Zbiór testowy')\n",
        "print(f'Liczba zdjęć H1 {len(os.listdir(H1_test))}')\n",
        "print(f'Liczba zdjęć H2 {len(os.listdir(H2_test))}')\n",
        "print(f'Liczba zdjęć H3 {len(os.listdir(H3_test))}')\n",
        "print(f'Liczba zdjęć H5 {len(os.listdir(H5_test))}')\n",
        "print(f'Liczba zdjęć H6 {len(os.listdir(H6_test))}')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e_p7veKCHOiu"
      },
      "outputs": [],
      "source": [
        "train_dataset, valid_dataset = image_dataset_from_directory(directory_train, validation_split=0.2,\n",
        "                                       subset='both',\n",
        "                                       seed=1410,\n",
        "                                       image_size=(256, 256),\n",
        "                                       label_mode='categorical',\n",
        "                                      color_mode=\"rgb\"\n",
        "                                       )\n",
        "\n",
        "test_dataset = image_dataset_from_directory(directory_test, seed=1410,\n",
        "                                       image_size=(256, 256),\n",
        "                                       label_mode='categorical',\n",
        "                                      color_mode=\"rgb\"\n",
        "                                       )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TCArTUyBY-Vn"
      },
      "outputs": [],
      "source": [
        "data_augmentation_layers = [\n",
        "    layers.RandomFlip(\"horizontal\"),\n",
        "    layers.RandomRotation(0.1),\n",
        "]\n",
        "\n",
        "\n",
        "def data_augmentation(images):\n",
        "    for layer in data_augmentation_layers:\n",
        "        images = layer(images)\n",
        "    return images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDrg5oIPIGBm"
      },
      "outputs": [],
      "source": [
        "class_names = train_dataset.class_names\n",
        "print(class_names)\n",
        "\n",
        "%matplotlib inline\n",
        "fig, ax = plt.subplots(4,4, figsize=(10,10))\n",
        "\n",
        "\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(16):\n",
        "        augmented_images = data_augmentation(images)\n",
        "\n",
        "        ax = plt.subplot(4,4,i + 1)\n",
        "        plt.imshow(augmented_images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[int(np.argmax(labels[i]))])\n",
        "        plt.axis(\"off\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HY8g_00Ub4CE"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.map(\n",
        "    lambda img, label: (data_augmentation(img), label),\n",
        "    num_parallel_calls=tf_data.AUTOTUNE,\n",
        ")\n",
        "\n",
        "# Prefetching samples in GPU memory helps maximize GPU utilization.\n",
        "train_dataset = train_dataset.prefetch(tf_data.AUTOTUNE)\n",
        "valid_dataset = valid_dataset.prefetch(tf_data.AUTOTUNE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eu9BMkYdKdV9"
      },
      "outputs": [],
      "source": [
        "base_model = Xception(\n",
        "    weights='imagenet',\n",
        "    input_shape=(256, 256, 3),\n",
        "    include_top=False)\n",
        "\n",
        "base_model.trainable = False\n",
        "\n",
        "plot_model(base_model, show_shapes=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SIixWfdWcx9Q"
      },
      "outputs": [],
      "source": [
        "#warstwy wejściowe\n",
        "inputs = Input(shape=(256, 256, 3))\n",
        "x = xception.preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "x = layers.Dense(5, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs ,x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aI_i-ABLLGpr"
      },
      "outputs": [],
      "source": [
        "# Kompilacja\n",
        "model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
        "\n",
        "# Uczenie sieciSS\n",
        "history = model.fit(train_dataset, epochs=30, validation_data=valid_dataset,\n",
        "                    batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7vA4TkTLMJR"
      },
      "outputs": [],
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.0, 1])\n",
        "plt.legend(loc='lower right')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r-fB7ULeLO8z"
      },
      "outputs": [],
      "source": [
        "result = model.evaluate(test_dataset, return_dict=True)\n",
        "\n",
        "print(f'Dokładność modelu {round(result[\"accuracy\"]*100,2)}%')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VT2P3GQ6LHic"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(test_dataset)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.concatenate([y for x, y in test_dataset], axis=0)\n",
        "y_true = np.argmax(y_true, axis=1)  # Przekształcenie na etykiety klas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbHwwqkMLYMU"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, balanced_accuracy_score, f1_score\n",
        "\n",
        "# Załóżmy, że y_true to prawdziwe etykiety, a y_pred to przewidziane etykiety\n",
        "confusion_matrix = confusion_matrix(y_true, y_pred)\n",
        "print(confusion_matrix)\n",
        "bac = balanced_accuracy_score(y_true, y_pred)\n",
        "print(bac)\n",
        "f1_macro = f1_score(y_true, y_pred, average='macro')\n",
        "f1_weighted = f1_score(y_true, y_pred, average='weighted')\n",
        "f1_micro = f1_score(y_true, y_pred, average='micro')\n",
        "\n",
        "print(f'F1 Score (Macro): {f1_macro}')\n",
        "print(f'F1 Score (Weighted): {f1_weighted}')\n",
        "print(f'F1 Score (Micro): {f1_micro}')\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1Hs9CaLIUb-9p0zh64XKE0Buh6pGLWndP",
      "authorship_tag": "ABX9TyPT5F0iumzYcZ8N7n1VFnr4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}